services:
  frontend:
    build: ./client
    ports: [ "80:80" ]
    depends_on: [ backend ]
    restart: always
  backend:
    build:
      context: ./server
      no_cache: true
    ports: [ "8080:8080" ]
    environment:
      DATABASE_URL: postgresql://root:secret@postgres:5432/project_monopoly?sslmode=disable
      DOCS_DIR: /data/docs
      OLLAMA_URL: http://ollama:11434/v1/chat/completions
      OLLAMA_HOST: http://ollama:11434
      OLLAMA_MODEL: qwen2.5:3b-instruct
      LLM_PROVIDER: ollama
      GEMINI_API_KEY: "${GEMINI_API_KEY}"
      GEMINI_MODEL: gemini-2.0-flash
      DEEPSEEK_API_KEY: "${DEEPSEEK_API_KEY}"
    volumes:
      - docs_data:/data/docs
      - docs_data:/app/uploads/docs
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
    restart: always
  python:
    build: ./server/python
    shm_size: '2gb'
    environment:
      DOCS_DIR: /data/docs
      INSTAGRAM_USERNAME: "${INSTAGRAM_USERNAME}"
      INSTAGRAM_PASSWORD: "${INSTAGRAM_PASSWORD}"
      DATABASE_URL: postgresql://root:secret@postgres:5432/project_monopoly
      CELERY_BROKER_URL: "amqp://guest:guest@rabbitmq:5672//"
      CELERY_RESULT_BACKEND: "rpc://"
    volumes:
      - ./server/python:/app
      - docs_data:/data/docs
      - docs_data:/app/uploads/docs
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
    restart: always
  postgres:
    image: pgvector/pgvector:pg15
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: project_monopoly
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./server/internal/db/migration:/migration

    ports: [ "5434:5432" ]
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U root -d project_monopoly" ]
      interval: 5s
      timeout: 3s
      retries: 20
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: always
    ports: [ "11434:11434" ]
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - "OLLAMA_ORIGINS=*"
      - "OLLAMA_KEEP_ALIVE=10m"
      - "OLLAMA_NUM_THREADS=9"
      - "OLLAMA_NUM_CTX=8024"
    cpus: "8"
    mem_limit: "32g"
    entrypoint: [ "ollama", "serve" ]
  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    restart: always
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: [ "CMD", "rabbitmq-diagnostics", "-q", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
volumes:
  postgres_data:
  ollama_data:
  docs_data:
