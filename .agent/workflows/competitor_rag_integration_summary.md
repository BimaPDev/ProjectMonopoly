# Comprehensive Technical Summary: Competitor Data Integration & RAG Pipeline
**Date:** 2025-12-16
**Objective:** End-to-end integration of scraped social media data into the AI RAG system, resolving data formatting, consistency, and retrieval permission issues.

---

## 1. RAG Ingestion Pipeline (New Feature)
**File:** `server/python/socialmedia/rag_ingest.py`
**Description:** Created a new module to convert raw JSON metrics into a human-readable text report for the AI.

```python
def generate_competitor_report(competitor_data):
    """Generates a text report from competitor data."""
    username = competitor_data.get('username', 'Unknown')
    # ... extraction of stats ...
    
    report = f"COMPETITOR ANALYSIS REPORT\n"
    report += f"Generated on: {last_updated}\n"
    report += f"Target Competitor: @{username}\n"
    report += f"Platform: Instagram\n\n"
    report += f"--- KEY METRICS ---\n"
    report += f"Followers: {followers:,}\n"
    report += f"Engagement Rate: {engagement_rate:.2f}%\n"
    # ... adds recent posts details ...
    return report

def ingest_competitor_report(username, report_text, user_id, group_id=None):
    """Ingests generated report into workshop_documents table."""
    # ... SHA256 calculation ...
    with psycopg.connect(DATABASE_URL) as conn:
        with conn.cursor() as cur:
            # Insert Document
            cur.execute("""
                INSERT INTO workshop_documents
                (user_id, group_id, filename, mime, size_bytes, sha256, storage_url, status, ...)
                VALUES (%s, %s, %s, 'text/plain', %s, %s, '', 'ready', ...)
            """, (user_id, group_id or 1, filename, len(report_text), content_sha256))
            
            # Insert Chunks for Search
            cur.execute("INSERT INTO workshop_chunks ...")
```

---

## 2. Ingestion Trigger Integration
**File:** `server/python/socialmedia/upload_to_db.py`
**Description:** Modified the main scraping script to trigger RAG ingestion immediately after saving data to the database.

```python
# Inside upload_posts_to_db function...

# After stats update:
print(f"Updated stats for @{username}: {followers} followers...")

# --- RAG Ingestion Block ---
try:
    user_id = None
    group_id = None
    
    # Dynamic Owner Lookup: Find who owns this competitor
    with conn.cursor() as cur:
        cur.execute("""
            SELECT user_id, group_id 
            FROM user_competitors 
            WHERE competitor_id = %s LIMIT 1
        """, (competitor_id,))
        drow = cur.fetchone()
        if drow:
            user_id, group_id = drow
    
    if user_id:
         # Prepare data
         report_data = {
             'username': username,
             'followers': followers,
             'engagement_rate': engagement_rate,
             'posts': posts_list
             # ...
         }
         
         # Import and run ingestion
         try:
             from socialmedia.rag_ingest import generate_competitor_report, ingest_competitor_report
         except ImportError:
             from rag_ingest import generate_competitor_report, ingest_competitor_report
         
         report_text = generate_competitor_report(report_data)
         ingest_competitor_report(username, report_text, user_id, group_id)
         print(f"RAG Report generated and ingested for owner user_id={user_id}")

except Exception as rag_err:
    print(f"⚠️ RAG Ingest failed (non-fatal): {rag_err}")
```

---

## 3. Database Search Logic Update
**File:** `server/internal/db/query/workshop.sql`
**Description:** Removed strict User ID restrictions to allow **Group-Wide Access** to documents. This enables users to see RAG reports generated by the background system worker.

```sql
-- name: SearchChunks :many
WITH p AS ( ... )
SELECT ...
FROM workshop_chunks c
JOIN workshop_documents d ON d.id = c.document_id, p
WHERE d.group_id = p.group_id  -- REMOVED: AND d.user_id = p.user_id
  AND (
    c.tsv @@ websearch_to_tsquery('english', p.q)
    OR c.content ILIKE '%' || p.q || '%'
  )
ORDER BY rank DESC;
```

---

## 4. Backend Consistency Fixes
**File:** `server/internal/utils/social.go`
**Description:** Enforced lowercase platform names to prevent duplicate "Instagram" vs "instagram" entries.

```go
func ParseSocialInput(input, platform string) (*ParsedSocial, error) {
    // ...
    return &ParsedSocial{
        Platform:   strings.ToLower(platform), // Enforce lowercase
        Username:   username,
        ProfileURL: profileURL,
    }, nil
}
```

**File:** `server/internal/handlers/competitor.go`
**Description:** Fixed struct field mapping for SQLC generated code.

```go
// Corrected param field name from 'Username' to 'Lower' to match schema
existing, err := queries.GetCompetitorByPlatformUsername(c.Request.Context(), db.GetCompetitorByPlatformUsernameParams{
    Platform: parsed.Platform,
    Lower:    parsed.Username, // Was 'Username'
})
```

---

## 5. Frontend UI & Model Updates
**File:** `client/src/components/competitors-page.tsx`
**Description:** Enhanced status Logic for clear user feedback.

```tsx
// Better scraping status calculation
const isScraping = !competitor.last_checked || Number(competitor.followers) === 0;

// ... in JSX ...
{isScraping ? (
  <span className="...">Scraping...</span>
) : (
  <span className="...">Processing...</span>
)}
```

**File:** `client/src/components/Ai-page.tsx`
**Description:** Updated the hardcoded AI model to one that is installed and working.

```tsx
const requestBody = {
    // ...
    model: "qwen2.5:3b-instruct", // Swapped from "gemma:latest"
    mode: "opinion",
    // ...
};
```
